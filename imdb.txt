import pandas as pd 
import numpy as np

from keras.datasets import imdb
from keras.layers import Dense,Embedding,Flatten
from keras.models import Sequential
from keras.utils import pad_sequences

max_words=10000
(x_train,y_train),(x_test,y_test)=imdb.load_data(num_words=max_words)

x_train=pad_sequences(x_train,maxlen=200)
x_test=pad_sequences(x_test,maxlen=200)

model=Sequential([
    Embedding(input_dim=max_words,output_dim=32,input_length=200),
    Flatten(),
    Dense(1,activation="sigmoid")
])

model.compile(optimizer="adam",loss="binary_crossentropy",metrics=["accuracy"])

model.fit(x_train,y_train,epochs=5,validation_split=0.2)

loss,accuracy=model.evaluate(x_test,y_test)
print(loss)
print(accuracy)

pred=model.predict(x_test)
print(pred)

binary_pred=np.round(pred)
print(binary_pred)

n=int(input("enter label : "))
if binary_pred[n]==0:
    print("negative")
else:
    print("positive")